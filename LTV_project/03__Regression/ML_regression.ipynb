{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import random\n",
    "from collections import Counter\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "from keras.models import Sequential, Model, load_model\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "158720/160014 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "# Load oversampled X\n",
    "oversampled_X_train = np.load('../Data/oversampled_X_train.npy')\n",
    "# Load oversampled y\n",
    "oversampled_y_train = np.load('../Data/overssampled_y_train.npy')\n",
    "# load smoted_data\n",
    "smoted_X_y = np.load('../Data/smoted_train_X_and_y.npy')\n",
    "# load test set\n",
    "norm_test_x = np.load('../Data/norm_test.npy')\n",
    "dim_reduced_test_x = np.load('../Data/autoencoded_data_test.npy')\n",
    "y_test = np.load('../Data/y_test.npy')\n",
    "\n",
    "def find_sim_buyers(data, label, model):\n",
    "    non_buyers = data[label==0]\n",
    "    probability = model.predict_proba(non_buyers)\n",
    "    index = np.where(np.logical_and(probability>=0.45, probability<0.5))[0]\n",
    "    return non_buyers[index]\n",
    "\n",
    "mlp_classification_oversample = load_model('../02__Classification/mlp_classification_oversample.h5')\n",
    "mlp_classification_smote = load_model('../02__Classification/mlp_classification_smote.h5')\n",
    "\n",
    "sim_buyers_x = find_sim_buyers(oversampled_X_train, oversampled_y_train, mlp_classification_oversample)\n",
    "sim_buyers_y = np.zeros((len(sim_buyers_x),1))\n",
    "\n",
    "# select buyers only\n",
    "buyer_index = oversampled_y_train>0\n",
    "\n",
    "oversampled_X_regression = oversampled_X_train[buyer_index]\n",
    "oversampled_y_regression = oversampled_y_train[buyer_index]\n",
    "oversampled_y_regression = oversampled_y_regression.reshape((oversampled_y_regression.shape[0],1))\n",
    "\n",
    "oversampled_X_regression = np.concatenate((oversampled_X_regression, sim_buyers_x))\n",
    "oversampled_y_regression = np.vstack((oversampled_y_regression,sim_buyers_y))\n",
    "\n",
    "smote_x = smoted_X_y[:,:-1]\n",
    "smote_y = smoted_X_y[:,-1]\n",
    "\n",
    "sim_buyers_xsmote = find_sim_buyers(smote_x, smote_y, mlp_classification_smote)\n",
    "sim_buyers_ysmote = np.zeros((len(sim_buyers_xsmote),1))\n",
    "\n",
    "# select buyers only\n",
    "buyer_index2 = smote_y>0\n",
    "\n",
    "xsmote_regression = smote_x[buyer_index2]\n",
    "ysmote_regression = smote_y[buyer_index2]\n",
    "ysmote_regression = ysmote_regression.reshape((ysmote_regression.shape[0],1))\n",
    "\n",
    "xsmote_regression = np.concatenate((xsmote_regression, sim_buyers_xsmote))\n",
    "ysmote_regression = np.vstack((ysmote_regression,sim_buyers_ysmote))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling w/ Random Forest Regression & XGBoostRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf_model = RandomForestRegressor(random_state=42,  \n",
    "                             n_estimators=30,\n",
    "                             max_depth=40, \n",
    "                             min_samples_split=3, \n",
    "                             min_samples_leaf=2, \n",
    "                             bootstrap=True)\n",
    "\n",
    "rf_model2 = RandomForestRegressor(random_state=42,  \n",
    "                             n_estimators=30,\n",
    "                             max_depth=40, \n",
    "                             min_samples_split=3, \n",
    "                             min_samples_leaf=2, \n",
    "                             bootstrap=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = XGBRegressor(max_depth=40, seed=42)\n",
    "xgb_model2 = XGBRegressor(max_depth=40, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rstudio/efs/anaconda3/envs/dl/lib/python3.6/site-packages/ipykernel_launcher.py:1: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/home/rstudio/efs/anaconda3/envs/dl/lib/python3.6/site-packages/ipykernel_launcher.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=40,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=2, min_samples_split=3,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=1,\n",
       "           oob_score=False, random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_model.fit(oversampled_X_regression, oversampled_y_regression)\n",
    "rf_model2.fit(xsmote_regression, ysmote_regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, colsample_bylevel=1, colsample_bytree=1, gamma=0,\n",
       "       learning_rate=0.1, max_delta_step=0, max_depth=40,\n",
       "       min_child_weight=1, missing=None, n_estimators=100, nthread=-1,\n",
       "       objective='reg:linear', reg_alpha=0, reg_lambda=1,\n",
       "       scale_pos_weight=1, seed=42, silent=True, subsample=1)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_model.fit(oversampled_X_regression, oversampled_y_regression,\n",
    "              eval_set=[(norm_test_x, y_test)], \n",
    "              eval_metric=['rmse', 'mae'], \n",
    "              early_stopping_rounds=10, verbose=False)\n",
    "xgb_model2.fit(xsmote_regression, ysmote_regression,\n",
    "              eval_set=[(dim_reduced_test_x, y_test)], \n",
    "              eval_metric=['rmse', 'mae'], \n",
    "              early_stopping_rounds=10, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rmse(targets, predictions):\n",
    "    return np.sqrt(((predictions - targets) ** 2).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nrmse for all spenders using random forest trained on oversampled data:  1.5450\n",
      "nrmse for all spenders using random forest trained on smote data:  1.5279\n",
      "nrmse for all spenders using XGB trained on oversampled data:  1.6992\n",
      "nrmse for all spenders using XGB trained on smote data:  1.5696\n"
     ]
    }
   ],
   "source": [
    "spender_test_index = y_test>0\n",
    "\n",
    "mean_ltv = y_test[spender_test_index].mean()\n",
    "rf_pred_os = rf_model.predict(norm_test_x[spender_test_index])\n",
    "rf_pred_smote = rf_model2.predict(dim_reduced_test_x[spender_test_index])\n",
    "xgb_pred_os = xgb_model.predict(norm_test_x[spender_test_index])\n",
    "xgb_pred_smote = xgb_model2.predict(dim_reduced_test_x[spender_test_index])\n",
    "\n",
    "rf_nrmse_all_os = rmse(y_test[spender_test_index].reshape((rf_pred_os.shape)), rf_pred_os)/mean_ltv\n",
    "rf_nrmse_all_smote = rmse(y_test[spender_test_index].reshape((rf_pred_smote.shape)), rf_pred_smote)/mean_ltv\n",
    "xgb_nrmse_all_os = rmse(y_test[spender_test_index].reshape((xgb_pred_os.shape)), xgb_pred_os)/mean_ltv\n",
    "xgb_nrmse_all_smote = rmse(y_test[spender_test_index].reshape((xgb_pred_smote.shape)), xgb_pred_smote)/mean_ltv\n",
    "print('nrmse for all spenders using random forest trained on oversampled data: ', '%.4f'%rf_nrmse_all_os)\n",
    "print('nrmse for all spenders using random forest trained on smote data: ', '%.4f'%rf_nrmse_all_smote)\n",
    "print('nrmse for all spenders using XGB trained on oversampled data: ', '%.4f'%xgb_nrmse_all_os)\n",
    "print('nrmse for all spenders using XGB trained on smote data: ', '%.4f'%xgb_nrmse_all_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nrmse for the Premium Users using random forest trained on oversampled data:  2.1001\n",
      "nrmse for the Premium Users using random forest trained on smote data:  2.1152\n",
      "nrmse for the Premium Users using XGB trained on oversampled data:  2.5021\n",
      "nrmse for the Premium Users using XGB trained on smote data:  2.4624\n"
     ]
    }
   ],
   "source": [
    "premium_index = np.where(np.logical_and(y_test>30, y_test<=70))[0]\n",
    "\n",
    "rf_pred_os_prem = rf_model.predict(norm_test_x[premium_index])\n",
    "rf_pred_smote_prem = rf_model2.predict(dim_reduced_test_x[premium_index])\n",
    "xgb_pred_os_prem = xgb_model.predict(norm_test_x[premium_index])\n",
    "xgb_pred_smote_prem = xgb_model2.predict(dim_reduced_test_x[premium_index])\n",
    "\n",
    "rf_nrmse_os_prem = rmse(y_test[premium_index].reshape((rf_pred_os_prem.shape)), rf_pred_os_prem)/mean_ltv\n",
    "rf_nrmse_smote_prem = rmse(y_test[premium_index].reshape((rf_pred_smote_prem.shape)), rf_pred_smote_prem)/mean_ltv\n",
    "xgb_nrmse_os_prem = rmse(y_test[premium_index].reshape((xgb_pred_os_prem.shape)), xgb_pred_os_prem)/mean_ltv\n",
    "xgb_nrmse_smote_prem = rmse(y_test[premium_index].reshape((xgb_pred_smote_prem.shape)), xgb_pred_smote_prem)/mean_ltv\n",
    "print('nrmse for the Premium Users using random forest trained on oversampled data: ', '%.4f'%rf_nrmse_os_prem)\n",
    "print('nrmse for the Premium Users using random forest trained on smote data: ', '%.4f'%rf_nrmse_smote_prem)\n",
    "print('nrmse for the Premium Users using XGB trained on oversampled data: ', '%.4f'%xgb_nrmse_os_prem)\n",
    "print('nrmse for the Premium Users using XGB trained on smote data: ', '%.4f'%xgb_nrmse_smote_prem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nrmse for the HIGH SPENDERS using random forest trained on oversampled data:  5.9245\n",
      "nrmse for the HIGH SPENDERS using random forest trained on smote data:  5.8797\n",
      "nrmse for the HIGH SPENDERS using XGB trained on oversampled data:  6.3903\n",
      "nrmse for the HIGH SPENDERS using XGB trained on smote data:  6.2445\n"
     ]
    }
   ],
   "source": [
    "rf_pred_os_hi = rf_model.predict(norm_test_x[y_test>100])\n",
    "rf_pred_smote_hi = rf_model2.predict(dim_reduced_test_x[y_test>100])\n",
    "xgb_pred_os_hi = xgb_model.predict(norm_test_x[y_test>100])\n",
    "xgb_pred_smote_hi = xgb_model2.predict(dim_reduced_test_x[y_test>100])\n",
    "\n",
    "rf_nrmse_os_hi = rmse(y_test[y_test>100].reshape((rf_pred_os_hi.shape)), rf_pred_os_hi)/mean_ltv\n",
    "rf_nrmse_smote_hi = rmse(y_test[y_test>100].reshape((rf_pred_smote_hi.shape)), rf_pred_smote_hi)/mean_ltv\n",
    "xgb_nrmse_os_hi = rmse(y_test[y_test>100].reshape((xgb_pred_os_hi.shape)), xgb_pred_os_hi)/mean_ltv\n",
    "xgb_nrmse_smote_hi = rmse(y_test[y_test>100].reshape((xgb_pred_smote_hi.shape)), xgb_pred_smote_hi)/mean_ltv\n",
    "print('nrmse for the HIGH SPENDERS using random forest trained on oversampled data: ', '%.4f'%rf_nrmse_os_hi)\n",
    "print('nrmse for the HIGH SPENDERS using random forest trained on smote data: ', '%.4f'%rf_nrmse_smote_hi)\n",
    "print('nrmse for the HIGH SPENDERS using XGB trained on oversampled data: ', '%.4f'%xgb_nrmse_os_hi)\n",
    "print('nrmse for the HIGH SPENDERS using XGB trained on smote data: ', '%.4f'%xgb_nrmse_smote_hi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
